
#### 限流： 对自己进行保护
1. 不能预设死一个限流值，需要收集cpu、耗时等负载信息来动态丢弃请求， 先丢弃低优先级的，再丢弃高优先级的请求
2. 由于现在都是集群化部署，就需要分布式限流：向redis 批量申请quota , 再利用max-min-fairness 算法保证各个节点批量申请的quota 值的合理性。同时动态设定租户的
3. 限流后，返回特定的错误码给client, 比如429 ，这样client 可以去做善意减少请求，随机backoff。因为过多的请求，服务器也需要花费资源去回应的。

#### 熔断：对下游服务进行保护
1.  不断统计QPS\错误率达到一定的情况下，熔断器打开，拒绝请求，不会发grpc 给下游服务。googel sre 算法保证比较平滑的拒绝或放通请求, 避免请求瞬时过高过低的情况。
2. gutter  kafaka: 一大一小双熔断方式，节约硬件资源

#### 降级：提供有损服务
1. 根据服务的重要性划分，把不重要的服务变得不可见或者返回低质量的数据。由BFF 在聚合数据时，对一些不重要的服务填充一些事先缓存的数据。
1. UI 端需要正确解析“低质量或者空的” 降级数据。提前约定好降级服务器数据。
2. sop 手册：需要演练手动恢复服务。
#### 重试：
1. 限制重试的次数，限制请求的流量是正常的1.1倍。
2. 仅在失败层进行重试，预定全局错误码, 上层处理此类错误不再重试，避免顶层级联重试、引发风暴。
3. 重试的策略，也可以由服务端根据自己负载情况，response （grpc metadata ）返回一些信息给client 端，主动提示client 如何重试。
#### 负载：
1. 通过cpu、latency、inflight 实时数据进行打分， p2c 算法随机取两个节点来比较分数。同时要考虑衰减来解决“黑名单”问题。

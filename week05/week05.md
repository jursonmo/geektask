
总结限流，熔断，降级的常用方式，重试的注意事项，负载均衡的常用方式。

#### 限流： 对自己进行保护， 算法: 令牌桶、漏桶

1. 不能预设死一个限流值，需要收集cpu、耗时等负载信息来动态丢弃请求， 先丢弃低优先级的，再丢弃高优先级的请求。 
2. cpu 负载通过滑动窗口来计算。 
3. 在服务器能接受的负载压力下，尽量最大化服务， 利特尔法则： L= rw 计算出一个值，超过这个值，就可以丢弃请求。
4. 由于现在都是集群化部署，就需要分布式限流：向redis 批量申请quota , 再利用max-min-fairness 算法保证各个节点批量申请的quota 值的合理性。同时动态设定租户的
5. 限流后，返回特定的错误码给client, 比如429 ，这样client 可以去做善意减少请求，随机backoff。因为过多的请求，服务器也需要花费资源去回应的。

#### 熔断：对下游服务进行保护
1.  不断统计QPS\错误率达到一定的情况下，熔断器打开，拒绝请求，不会发grpc 给下游服务。
2.  googel sre: max(0, (requests - K*accepts) / (requests + 1)) 算法保证比较平滑的拒绝或放通请求, 避免请求瞬时过高过低的情况。
3. gutter  kafaka: 一大一小双熔断方式，节约硬件资源

#### 降级：提供有损服务
1. 根据服务的重要性划分，把不重要的服务变得不可见或者返回低质量的数据。由BFF 在聚合数据时，对一些不重要的服务填充一些事先缓存的数据。
1. UI 端需要正确解析“低质量或者空的” 降级数据。提前约定好降级服务器数据格式，避免前端解析出错或者显示空白。
2. sop 手册：需要演练手动恢复服务。
#### 重试：
1. 限制重试的次数，限制请求的流量是正常的1.1倍。
2. 仅在失败层进行重试，预定全局错误码, 上层处理此类错误不再重试，避免顶层级联重试、引发风暴。
3. 重试的策略，也可以由服务端根据自己负载情况，response （grpc metadata ）返回一些信息给client 端，主动提示client 采取什么策略进行重试。
#### 负载：
1. 通过cpu、latency、inflight 实时数据进行打分， p2c 算法随机取两个节点来比较分数。
2. 对于分数比较低的节点，要考虑衰减来解决“永久黑名单”问题。
